\documentclass[12pt]{article}

% Packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{pgfplots}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % Adjust margins
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{siunitx}

% Title
\title{CS312 Project 3 Report}
\author{Brock Gregersen}
\date{\today}
\pgfplotsset{compat=1.18}
\begin{document}

\maketitle
\tableofcontents

\newpage

\section{Algorithm Analysis}

\subsection{List Based Priority Queue}

\begin{algorithm}
    \caption{ListPriorityQueue.\textsc{Push}}
    \begin{algorithmic}[1]
        \State Append (node, priority) to queue
    \end{algorithmic}
\end{algorithm}

The priority queue uses Python's default list data structure to store the nodes
and their priorities. The \texttt{list.append()} function runs in $O(1)$ time complexity.

\begin{algorithm}[H]
    \caption{ListPriorityQueue.\textsc{Pop}}
    \begin{algorithmic}[1]
        \If{\textsc{IsEmpty()}}
            \State \textbf{then return} None
        \EndIf
        \State min\_index $\gets$ 0
        \For{$i$ in queue} \Comment{runs n times}
            \If{queue[$i$][1] $<$ queue[min\_index][1]}
                \State min\_index $\gets i$
            \EndIf
        \EndFor
        \State \textbf{return} Remove and return queue[min\_index]
    \end{algorithmic}
\end{algorithm}

The \textsc{Pop} procedure uses a for loop to iterate through the queue list
to find the node with the minimum priority. The for loop runs $n$ times, leading
to a time complexity of $O(n)$. The remove function uses Python's \texttt{list.pop()}
function, which runs in $O(n)$ time.

\begin{algorithm}[H]
    \caption{ListPriorityQueue.\textsc{decrease\_key}}
    \begin{algorithmic}[1]
        \For{$i$ in queue} \Comment{runs max n times}
            \If{queue[$i$][0] = node}
                \State queue[$i$][1] $\gets$ new\_priority
                \State \textbf{break}
            \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}

The \textsc{decrease\_key} function uses a for loop to iterate through
the queue list to find the node with the matching node. The loop runs
at most $n$ times, and has only constant time operations inside, leading
to a time complexity of $O(n)$.

\newpage

\begin{table}[H]
    \centering
    \begin{threeparttable}
        \caption{Time and Space Complexity of List-Based Priority Queue}
        \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lll@{}}
            \toprule
            \textbf{Procedure} & \textbf{Time Complexity} & \textbf{Space Complexity} \\ \midrule
            \textsc{Push}      & $O(1)$                  & $O(1)$                    \\
            \textsc{Pop}       & $O(n)$                  & $O(1)$                    \\
            \textsc{decrease\_key} & $O(n)$              & $O(1)$                    \\
            \bottomrule
        \end{tabular*}
    \end{threeparttable}
\end{table}

Other than the queue list, only a constant amount of space is for min\_index
is used, leading to a space complexity of $O(1)$ for all procedures.

\newpage

\subsection{Heap Based Priority Queue}

\begin{algorithm}[H]
    \caption{HeapPriorityQueue.\textsc{Push}}
    \begin{algorithmic}[1]
        \State index $\gets$ \text{length}(heap)
        \State Append (node, priority) to heap
        \While{index $>$ 0} \Comment{runs max $\log{n}$ times}
            \If{heap[index][1] $<$ heap[$\lfloor \text{(index - 1) / 2} \rfloor$][1]}
                \State Swap heap[index] and heap[$\lfloor \text{(index - 1) / 2} \rfloor$]
                \State index $\gets$ $\lfloor \text{(index - 1) / 2} \rfloor$
            \Else
                \State \textbf{break}
            \EndIf
        \EndWhile
    \end{algorithmic}
\end{algorithm}

The heap is implemented as a Python list. The \textsc{Push} procedure appends the
node and priority to the end of the list in $O(1)$ time. The while loop runs $\log{n}$
times. Each iteration uses constant time operations, leading to a time complexity
of $O(\log{n})$.

\begin{algorithm}[H]
    \caption{heapPriorityQueue.\textsc{heap\_down}}
    \begin{algorithmic}[1]
        \State left $\gets$ index * 2 + 1
        \State right $\gets$ index * 2 + 2
        \State smallest $\gets$ index
        \If{left $<$ \text{length}(heap) \textbf{and} heap[left][1] $<$ heap[smallest][1]}
            \State smallest $\gets$ left
        \EndIf
        \If{right $<$ \text{length}(heap) \textbf{and} heap[right][1] $<$ heap[smallest][1]}
            \State smallest $\gets$ right
        \EndIf
        \If{smallest $\neq$ index}
            \State Swap heap[index] and heap[smallest]
            \State \textsc{heap\_down}(smallest) \Comment{max recursion depth of $\log{n}$}
        \EndIf
    \end{algorithmic}
\end{algorithm}

\textsc{heap\_down} takes as an input the index of the node to move down the heap.
It's initial input index from \textsc{Pop} is 0. With each recursive call,
the index is multiplied by 2. The function stops when the index is greater than
or equal to the length of the heap, so recursion will reach a maximum depth of
$\log{n}$. The function uses constant time operations, leading to a time complexity
of $O(\log{n})$.

\begin{algorithm}[H]
    \caption{HeapPriorityQueue.\textsc{Pop}}
    \begin{algorithmic}[1]
        \If{\textsc{IsEmpty()}}
            \State \textbf{then return} None
        \EndIf
        \State top $\gets$ heap[0]
        \State heap[0] $\gets$ heap[-1]
        \State \textbf{del} heap[-1]
        \State \textsc{heap\_down}(0) \Comment{O(log n)}
        \State \textbf{return} top
    \end{algorithmic}
\end{algorithm}

The \textsc{Pop} function uses the \textsc{heap\_down} maintain the heap property
after removing the top node. Otherwise, the function uses constant time operations,
leading to a time complexity of $O(\log{n})$.

\begin{algorithm}
    \caption{HeapPriorityQueue.\textsc{decrease\_key}}
    \begin{algorithmic}[1]
        \For{$i$ in heap} \Comment{runs max n times}
            \State heap[i][1] $\gets$ new\_priority
            \While {$i > 0$} \Comment{runs max $\log{n}$ times}
                \If{heap[i][1] $<$ heap[$\lfloor \text{(i - 1) / 2} \rfloor$][1]}
                    \State Swap heap[i] and heap[$\lfloor \text{(i - 1) / 2} \rfloor$]
                    \State i $\gets$ $\lfloor \text{(i - 1) / 2} \rfloor$
                \Else
                    \State \textbf{break}
                \EndIf
            \EndWhile
            \State \textbf{break}
        \EndFor
    \end{algorithmic}
\end{algorithm}

The \textsc{decrease\_key} function uses a for loop to iterate through the heap list
to find the node with the matching node. The loop to find the node runs at most $n$
times. The heap property is restored by the while loop, which runs a single time with a
maximum depth of $\log{n}$, leading to a time complexity of $O(n + \log{n})$ = $O(n)$.

\begin{table}[H]
    \centering
    \begin{threeparttable}
        \caption{Time and Space Complexity of Heap-Based Priority Queue}
        \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lll@{}}
            \toprule
            \textbf{Procedure} & \textbf{Time Complexity} & \textbf{Space Complexity} \\ \midrule
            \textsc{Push}      & $O(\log n)$ & $O(1)$        \\
            \textsc{Pop}       & $O(\log n)$ & $O(\log n)$   \\
            \textsc{decrease\_key} & $O(n)$  & $O(1)$        \\
            \bottomrule
        \end{tabular*}
    \end{threeparttable}
\end{table}

The heap based priority queue uses in place operations, so the space complexity is only
increased by recursive calls of \textsc{heap\_down}, leading to a space complexity of $O(\log{n})$ for
\textsc{heap\_down} and dependent functions and $O(1)$ for all other procedures.

\subsection{Dijkstra's Algorithm}

\begin{algorithm}[H]
    \caption{\textsc{Dijkstra}}
    \begin{algorithmic}[1]
        \State Initialize distances to all nodes to $\infty$ \Comment{O(V)}
        \State Initialize previous nodes to all nodes to None \Comment{O(V)}
        \State Initialize distance to start node to 0
        \State Initialize priority queue with distance to start node \Comment{O(\textsc{Push}(V))}
        \While{priority queue is not empty} \Comment{runs V times}
            \State node, distance $\gets$ \textsc{Pop} from priority queue \Comment{O(\textsc{Pop}(V))}
            \For{neighbor, weight in node.neighbors} \Comment{runs E times total}
                \State new\_distance $\gets$ distance + weight
                \If{new\_distance $<$ distances[neighbor]}
                    \State distances[neighbor] $\gets$ new\_distance
                    \State previous[neighbor] $\gets$ node
                    \State \textsc{decrease\_key}(neighbor, new\_distance) \Comment{O(\textsc{decrease\_key}(V))}
                \EndIf
            \EndFor
        \EndWhile

    \end{algorithmic}
\end{algorithm}

This implementation of Dijkstra's algorithm uses Python's dictionary data
structures to store each nodes current distance. This data structure
uses an underlying hash table, so the time complexity of operations on them is
$O(1)$. The while loop runs ends after all nodes have been visited, so it runs
$V$ times. The for loop runs for each edge, so it runs $E$ times. Factoring in
the \textsc{Push} operation inside the for loop, and the \textsc{Pop} operation
inside the while loop, the time complexity of the algorithm is $O(E * \textsc{push}(V)
 + V * \textsc{pop}(V) + \textsc{push}(V))$. Simplifying with the time complexity
of the operations in each priority queue implementation, the time complexity of
the algorithm is $O((E+V)\log V)$ for the heap based priority queue and $O(V^2)$
for the list based priority queue.

\begin{table}[H]
    \centering
    \begin{threeparttable}
        \caption{Time and Space Complexity of Dijkstra's Algorithm}
        \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}llc@{}}
            \toprule
            \textbf{Procedure} & \textbf{Time Complexity} & \textbf{Space Complexity} \\ \midrule
            \textsc{Dijkstra} (heap)  & $O((E+V)\log V)$        & $O(V)$                    \\
            \textsc{Dijkstra} (list)  & $O(V^2)$                & $O(V)$                    \\
            \bottomrule
        \end{tabular*}
    \end{threeparttable}
\end{table}

For both implementations, the space is only increased by the visited set and
distances dictionary, which each have a max size of $V$, leading to a space
complexity of $O(V)$ in both cases. 

\section{Empirical Analysis}

\subsection{Runtime Data}

\begin{table}[H]
    \centering
    \begin{threeparttable}
        \caption{Empirical Analysis of Dijkstra's Algorithm (low density)}
        \begin{tabular}{@{}rSrSS@{}}
            \toprule
            \textbf{n} & \textbf{Density} & \textbf{\# Edges} & \textbf{Heap Time (s)} & \textbf{List Time (s)} \\ \midrule
            1000   & 0.01   & 10000   &   0.038 &   0.038 \\
            5000   & 0.002  & 50000   &   0.894 &   0.879 \\
            10000  & 0.001  & 100000  &   3.577 &   3.591 \\
            50000  & 0.0002 & 500000  &  75.164 & 124.013 \\
            100000 & 0.0001 & 1000000 & 570.202 & 750.442 \\
            \bottomrule
        \end{tabular}
    \end{threeparttable}
\end{table}

\begin{table}[h!]
    \centering
    \begin{threeparttable}
        \caption{Empirical Analysis of Dijkstra's Algorithm (High Density)}
        \begin{tabular}{@{}ccrSS@{}}
            \toprule
            \textbf{n} & \textbf{Density} & \textbf{\# Edges} & \textbf{Heap Time (s)} & \textbf{List Time (s)} \\ \midrule
            1000 & 1 & 999000   &  0.454 &  0.244 \\
            2000 & 1 & 3998000  &  2.767 &  1.453 \\
            3000 & 1 & 8997000  &  7.866 &  4.555 \\
            4000 & 1 & 15996000 & 16.966 &  9.647 \\
            5000 & 1 & 24995000 & 29.308 & 16.394 \\
            6000 & 1 & 35994000 & 48.037 & 25.781 \\
            \bottomrule
        \end{tabular}
    \end{threeparttable}
\end{table}

\subsection{Discussion}

The runtime data shows that for low density graphs, the heap based priority queue
has a slightly faster runtime than the list based priority queue. This makes sense 
since the heap based priority queue has a time complexity of $O((E+V)\log V)$, while
the list based priority queue has a time complexity of $O(V^2)$. For low density
graphs, the number of edges is not much greater than the number of vertices, so
the heap based priority queue has a lower time complexity. For high density graphs,
the list based priority queue has a faster runtime than the heap based priority queue.
This also makes sense, because the number of edges is much greater than the number
of edges factors into the $O((E+V)\log V)$ time complexity of the heap based priority
queue, but not the $O(V^2)$ time complexity of the list based priority queue.

\end{document}